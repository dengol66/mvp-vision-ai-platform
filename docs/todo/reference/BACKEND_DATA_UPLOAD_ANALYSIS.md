# Backend Data Upload Analysis

**ë¶„ì„ ì¼ì‹œ**: 2025-11-20 15:00 KST
**ë¶„ì„ ë²”ìœ„**: Backendê°€ Trainer SDKë¡œë¶€í„° ë°›ì€ ë°ì´í„°ë¥¼ ì–´ë–»ê²Œ í•„ìš”í•œ ê³³ì— ì—…ë¡œë“œí•˜ëŠ”ì§€
**ê´€ë ¨ íŒŒì¼**: `platform/backend/app/api/training.py`, `training_subprocess.py`, `mlflow_client.py`, `models.py`

---

## Executive Summary

BackendëŠ” Trainer SDKë¡œë¶€í„° ë°›ì€ ë°ì´í„°(ë¡œê·¸, ë©”íŠ¸ë¦­, ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ, ê²°ê³¼)ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ì²˜ë¦¬í•©ë‹ˆë‹¤:

| ë°ì´í„° íƒ€ì… | ì €ì¥ì†Œ | Backend ì—­í•  | êµ¬í˜„ ìƒíƒœ | í…ŒìŠ¤íŠ¸ ìƒíƒœ |
|------------|--------|-------------|-----------|------------|
| **Logs** | DB + Loki | âœ… ë‘ ê³³ì— ëª¨ë‘ ì €ì¥ | 90% (LokiëŠ” ì„ íƒì ) | âœ… DB ì €ì¥ í…ŒìŠ¤íŠ¸ë¨, âŒ Loki ë¯¸í…ŒìŠ¤íŠ¸ |
| **Metrics** | DB + MLflow | âš ï¸ DBë§Œ ì €ì¥, MLflowëŠ” SDKê°€ ì§ì ‘ | 100% | âœ… DB ì €ì¥ í…ŒìŠ¤íŠ¸ë¨ |
| **Checkpoints** | S3 | âŒ ì—…ë¡œë“œ ì•ˆ í•¨ (ê²½ë¡œë§Œ ì €ì¥) | 100% | âœ… ê²½ë¡œ ì €ì¥ í…ŒìŠ¤íŠ¸ë¨ |
| **Results** | DB | âœ… ìµœì¢… ê²°ê³¼ ì €ì¥ | 100% | âœ… ì €ì¥ í…ŒìŠ¤íŠ¸ë¨ |
| **WebSocket** | Frontend | âœ… ì‹¤ì‹œê°„ ë¸Œë¡œë“œìºìŠ¤íŠ¸ | 100% | âŒ ë¯¸í…ŒìŠ¤íŠ¸ |

**í•µì‹¬ ë°œê²¬**:
- âœ… BackendëŠ” ë¡œê·¸ë¥¼ DBì™€ Loki ë‘ ê³³ì— ì €ì¥ (LokiëŠ” ì„ íƒì )
- âš ï¸ **MLflow ë©”íŠ¸ë¦­ì€ Backendê°€ ì—…ë¡œë“œí•˜ì§€ ì•ŠìŒ** - Trainer SDKê°€ ì§ì ‘ MLflowì— ë¡œê¹…
- âœ… ì²´í¬í¬ì¸íŠ¸ëŠ” SDKê°€ S3ì— ì—…ë¡œë“œ, BackendëŠ” ê²½ë¡œë§Œ DBì— ì €ì¥
- âœ… WebSocket ë¸Œë¡œë“œìºìŠ¤íŠ¸ êµ¬í˜„ë¨ (Frontend ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ìš©)

---

## 1. Log Upload Flow (Subprocess â†’ Backend â†’ DB + Loki)

### 1.1 Implementation

**íŒŒì¼**: `platform/backend/app/utils/training_subprocess.py`

#### 1.1.1 Log Collection (Lines 237-322)

```python
async def _monitor_process_logs(self, job_id: int, process: subprocess.Popen):
    """Monitor subprocess logs in background."""
    # Wrap stdout/stderr with UTF-8 encoding
    stdout_reader = io.TextIOWrapper(process.stdout.buffer, encoding='utf-8', errors='replace')
    stderr_reader = io.TextIOWrapper(process.stderr.buffer, encoding='utf-8', errors='replace')

    async def read_stream_async(reader, prefix):
        batch = []
        batch_size = 10  # Save every 10 lines

        while True:
            line = await loop.run_in_executor(None, read_one_line)
            if not line:
                break

            batch.append(line)

            # Save batch to DB when full
            if len(batch) >= batch_size:
                await self._save_logs_to_db(job_id, batch, prefix)
                batch = []
```

#### 1.1.2 Database Storage (Lines 323-373)

```python
async def _save_logs_to_db(self, job_id: int, lines: list[str], log_type: str):
    """Save log lines to database AND Loki (dual storage)."""

    def save_to_db():
        db = SessionLocal()
        try:
            log_entries = [
                models.TrainingLog(
                    job_id=job_id,
                    log_type=log_type,  # "stdout" or "stderr"
                    content=line,
                    created_at=datetime.utcnow()
                )
                for line in lines
            ]
            db.bulk_save_objects(log_entries)
            db.commit()
        finally:
            db.close()

    await loop.run_in_executor(None, save_to_db)

    # Also send to Loki if enabled
    if self.loki_enabled:
        await self._send_logs_to_loki(job_id, lines, log_type)
```

**Database Table**: `training_logs`
```python
class TrainingLog(Base):
    id = Column(Integer, primary_key=True)
    job_id = Column(Integer, ForeignKey("training_jobs.id"))
    log_type = Column(String(10))  # "stdout" or "stderr"
    content = Column(Text)
    created_at = Column(DateTime)
```

#### 1.1.3 Loki Integration (Lines 375-425)

```python
async def _send_logs_to_loki(self, job_id: int, lines: list[str], log_type: str):
    """Send log lines to Loki for real-time log aggregation."""

    url = f"{self.loki_url}/loki/api/v1/push"

    # Build Loki streams payload
    base_timestamp_ns = int(datetime.utcnow().timestamp() * 1_000_000_000)

    values = []
    for i, line in enumerate(lines):
        timestamp_ns = str(base_timestamp_ns + i * 1000)  # +1Î¼s per line
        values.append([timestamp_ns, line])

    stream = {
        "stream": {
            "job": "training",
            "job_id": str(job_id),
            "log_type": log_type,
            "source": "backend"
        },
        "values": values
    }

    payload = {"streams": [stream]}
    await loop.run_in_executor(None, lambda: requests.post(url, json=payload, timeout=5))
```

**Configuration**:
- `LOKI_URL`: Loki ì„œë²„ URL (default: `http://localhost:3100`)
- `LOKI_ENABLED`: Loki í™œì„±í™” ì—¬ë¶€ (default: `true`)

**Status**: âš ï¸ Optional - Lokiê°€ ì—†ì–´ë„ DBì—ëŠ” ì €ì¥ë¨

### 1.2 Log Query API

**íŒŒì¼**: `platform/backend/app/api/training.py:684-717`

```python
@router.get("/jobs/{job_id}/logs", response_model=list[training.TrainingLogResponse])
async def get_training_logs(job_id: int, limit: int = 500, log_type: str | None = None):
    """Get training logs for a job from database."""
    query = db.query(models.TrainingLog).filter(models.TrainingLog.job_id == job_id)
    if log_type in ["stdout", "stderr"]:
        query = query.filter(models.TrainingLog.log_type == log_type)
    logs = query.order_by(models.TrainingLog.created_at.desc()).limit(limit).all()
    return list(reversed(logs))
```

**Loki Query API**: `training.py:719-817`
```python
@router.get("/jobs/{job_id}/logs/loki")
async def get_training_logs_from_loki(job_id: int, limit: int = 1000):
    """Get training logs from Loki log aggregation system."""
    logql_query = f'{{job="training", job_id="{job_id}"}}'
    response = requests.get(f"{loki_url}/loki/api/v1/query_range", params={...})
```

### 1.3 Testing Status

| í…ŒìŠ¤íŠ¸ í•­ëª© | ìƒíƒœ | ì¦ê±° |
|------------|------|------|
| DB ì €ì¥ | âœ… í…ŒìŠ¤íŠ¸ë¨ | E2E í…ŒìŠ¤íŠ¸ Step 9: 10 logs retrieved |
| DB ì¡°íšŒ API | âœ… í…ŒìŠ¤íŠ¸ë¨ | `GET /jobs/28/logs` returned 10 logs |
| Loki ì „ì†¡ | âŒ ë¯¸í…ŒìŠ¤íŠ¸ | E2E í…ŒìŠ¤íŠ¸ì—ì„œ Loki í…ŒìŠ¤íŠ¸ ì—†ìŒ |
| Loki ì¡°íšŒ API | âŒ ë¯¸í…ŒìŠ¤íŠ¸ | Loki ì„œë²„ ì—†ì´ëŠ” í…ŒìŠ¤íŠ¸ ë¶ˆê°€ |

**ì¶”ì²œ ì‚¬í•­**:
- [ ] Loki í†µí•© í…ŒìŠ¤íŠ¸ ì¶”ê°€ (Docker Composeì— Loki í¬í•¨)
- [ ] Loki ì „ì†¡ ì‹¤íŒ¨ ì‹œ fallback ë™ì‘ í™•ì¸ (í˜„ì¬ warningë§Œ ì¶œë ¥)

---

## 2. Metric Upload Flow (ì„¤ê³„ vs ì‹¤ì œ êµ¬í˜„)

### 2.1 Critical Finding: MLflow ì—…ë¡œë“œ ê¸°ëŠ¥ ë¯¸êµ¬í˜„

**ì„¤ê³„ ì˜ë„** (`THIN_SDK_DESIGN.md:636-802`):
```
Trainer (SDK) â†’ Backend â†’ MLflow, Loki, Prometheus
                     â†’ Database
                     â†’ WebSocket (Frontend)

Backendê°€ ì²˜ë¦¬í•´ì•¼ í•˜ëŠ” ê²ƒ:
- report_progress() ë°›ìœ¼ë©´ â†’ MLflow log_metrics() + Prometheus + WebSocket
- report_completed() ë°›ìœ¼ë©´ â†’ MLflow end_run() + DB ì €ì¥ + WebSocket
```

**ì‹¤ì œ êµ¬í˜„ ìƒíƒœ**: âŒ **ì•„ì§ êµ¬í˜„ ì•ˆ ë¨**

**ì¦ê±° 1 - Backend MLflow Client** (`mlflow_client.py`):
```python
class MLflowClientWrapper:
    """Wrapper for MLflow client with error handling."""

    # READ-ONLY methodsë§Œ ì¡´ì¬
    def get_run_by_job_id(...)  # ì¡°íšŒë§Œ
    def get_run_metrics(...)     # ì¡°íšŒë§Œ
    def get_run_summary(...)     # ì¡°íšŒë§Œ

    # âŒ log_metric(), log_param(), log_artifact() ê°™ì€ ì—…ë¡œë“œ ë©”ì„œë“œ ì—†ìŒ!
```

**ì¦ê±° 2 - Grep ê²°ê³¼**:
```bash
# Backendì—ì„œ MLflow ì—…ë¡œë“œ ì½”ë“œ ê²€ìƒ‰
$ grep -r "mlflow.log_metric\|mlflow.log_param\|mlflow.start_run" platform/backend
# â†’ No matches found

# Trainerì—ì„œ MLflow ì—…ë¡œë“œ ì½”ë“œ ê²€ìƒ‰
$ grep -r "mlflow.log_metric\|mlflow.log_param\|mlflow.start_run" platform/trainers/ultralytics
# â†’ No matches found
```

**ê²°ë¡ **: **MLflow ë©”íŠ¸ë¦­ ì—…ë¡œë“œ ê¸°ëŠ¥ì´ ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.**

### 2.3 Backend's Role: Database Storage

Backend receives metrics via callback and stores in database.

**íŒŒì¼**: `platform/backend/app/api/training.py:1532-1640`

```python
@router.post("/jobs/{job_id}/callback/progress")
async def training_progress_callback(job_id: int, callback: training.TrainingProgressCallback):
    """Receive progress updates from Training Service."""

    # Store metrics in database
    if callback.metrics:
        metrics_dict = callback.metrics.dict()
        extra_metrics = metrics_dict.get('extra_metrics', {})

        metric = models.TrainingMetric(
            job_id=job_id,
            epoch=callback.current_epoch,
            step=None,
            loss=metrics_dict.get('loss') or extra_metrics.get('loss'),
            accuracy=metrics_dict.get('accuracy') or extra_metrics.get('accuracy'),
            learning_rate=metrics_dict.get('learning_rate') or extra_metrics.get('lr'),
            extra_metrics=extra_metrics if extra_metrics else metrics_dict,
            checkpoint_path=callback.checkpoint_path,
        )
        db.add(metric)
        db.commit()
```

**Database Table**: `training_metrics`
```python
class TrainingMetric(Base):
    id = Column(Integer, primary_key=True)
    job_id = Column(Integer, ForeignKey("training_jobs.id"))
    epoch = Column(Integer)
    step = Column(Integer, nullable=True)
    loss = Column(Float, nullable=True)
    accuracy = Column(Float, nullable=True)
    learning_rate = Column(Float, nullable=True)
    extra_metrics = Column(JSON, nullable=True)  # All other metrics
    checkpoint_path = Column(String(500), nullable=True)
    created_at = Column(DateTime)
```

### 2.4 MLflow Run ID Linking

Backend stores MLflow run_id for reference.

**íŒŒì¼**: `training.py:329-341, 1726-1727`

```python
# Auto-link MLflow run_id if not already linked
if not job.mlflow_run_id and job.status in ["running", "completed"]:
    mlflow_client = get_mlflow_client()
    mlflow_run = mlflow_client.get_run_by_job_id(job_id)
    if mlflow_run:
        job.mlflow_run_id = mlflow_run.info.run_id
        db.commit()

# Completion callback stores run_id
if callback.mlflow_run_id:
    job.mlflow_run_id = callback.mlflow_run_id
```

### 2.5 Testing Status

| í…ŒìŠ¤íŠ¸ í•­ëª© | ìƒíƒœ | ì¦ê±° |
|------------|------|------|
| SDK â†’ MLflow ë¡œê¹… | âš ï¸ SDK ë‚´ë¶€ (Backend ë¬´ê´€) | Trainer SDKê°€ ìˆ˜í–‰ |
| Callback ìˆ˜ì‹  | âœ… í…ŒìŠ¤íŠ¸ë¨ | E2E Step 6: 3 epochs with callbacks |
| DB ì €ì¥ | âœ… í…ŒìŠ¤íŠ¸ë¨ | E2E Step 6: TrainingMetric records created |
| MLflow run_id ì €ì¥ | âœ… í…ŒìŠ¤íŠ¸ë¨ | E2E Step 7: mlflow_run_id stored |
| MLflow ì¡°íšŒ API | âœ… í…ŒìŠ¤íŠ¸ë¨ | `GET /jobs/{id}/mlflow/metrics` works |

**í˜„ì¬ ìƒíƒœ**: âœ… Backendì˜ ì—­í• (DB ì €ì¥, run_id ë§í¬)ì€ ëª¨ë‘ ì •ìƒ ë™ì‘

---

## 3. Checkpoint Upload Flow (SDK â†’ S3, Backend stores paths)

### 3.1 Backend Does NOT Upload Checkpoints

**BackendëŠ” ì²´í¬í¬ì¸íŠ¸ë¥¼ ì—…ë¡œë“œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.** ê²½ë¡œë§Œ ì €ì¥í•©ë‹ˆë‹¤.

### 3.2 Actual Upload: Trainer SDK

**íŒŒì¼**: `platform/trainers/ultralytics/trainer_sdk.py` (ì˜ˆì‹œ)

```python
def upload_checkpoint(self, local_path: str, checkpoint_type: str, is_best: bool = False):
    """Upload checkpoint to S3."""
    s3_path = f"checkpoints/{self.job_id}/{checkpoint_type}.pt"
    storage_client.upload_file(local_path, s3_path)
    return s3_path
```

### 3.3 Backend's Role: Store Paths

Backend receives checkpoint paths via callbacks and stores in database.

**Progress Callback** (`training.py:1601-1603`):
```python
if callback.best_checkpoint_path:
    job.best_checkpoint_path = callback.best_checkpoint_path
```

**Completion Callback** (`training.py:1719-1722`):
```python
if callback.best_checkpoint_path:
    job.best_checkpoint_path = callback.best_checkpoint_path
if callback.last_checkpoint_path:
    job.last_checkpoint_path = callback.last_checkpoint_path
```

**Database Fields**:
```python
class TrainingJob(Base):
    best_checkpoint_path = Column(String(500), nullable=True)
    last_checkpoint_path = Column(String(500), nullable=True)
```

### 3.4 Testing Status

| í…ŒìŠ¤íŠ¸ í•­ëª© | ìƒíƒœ | ì¦ê±° |
|------------|------|------|
| SDK â†’ S3 ì—…ë¡œë“œ | âš ï¸ SDK ë‚´ë¶€ (mocked in test) | E2E uses mocked S3 paths |
| Path ìˆ˜ì‹  | âœ… í…ŒìŠ¤íŠ¸ë¨ | E2E Step 7: paths received in callback |
| DB ì €ì¥ | âœ… í…ŒìŠ¤íŠ¸ë¨ | E2E: best_checkpoint_path stored |

**í˜„ì¬ ìƒíƒœ**: âœ… Backendì˜ ì—­í• (ê²½ë¡œ ì €ì¥)ì€ ì •ìƒ ë™ì‘

---

## 4. Result Storage Flow (Backend â†’ DB)

### 4.1 Implementation

**íŒŒì¼**: `platform/backend/app/api/training.py:1642-1783`

```python
@router.post("/jobs/{job_id}/callback/completion")
async def training_completion_callback(job_id: int, callback: training.TrainingCompletionCallback):
    """Receive final completion callback from Training Service."""

    # Update job status
    if callback.exit_code is not None:
        job.status = "completed" if callback.exit_code == 0 else "failed"
    else:
        job.status = callback.status

    job.completed_at = datetime.utcnow()

    # Update final accuracy
    if callback.final_metrics:
        metrics_dict = callback.final_metrics.dict()
        extra_metrics = metrics_dict.get('extra_metrics', {})
        job.final_accuracy = metrics_dict.get('accuracy') or extra_metrics.get('accuracy')

    # Store checkpoint paths
    if callback.best_checkpoint_path:
        job.best_checkpoint_path = callback.best_checkpoint_path
    if callback.last_checkpoint_path:
        job.last_checkpoint_path = callback.last_checkpoint_path

    # Store MLflow run ID
    if callback.mlflow_run_id:
        job.mlflow_run_id = callback.mlflow_run_id

    # Store error information
    if callback.status == "failed":
        job.error_message = callback.error_message
        if callback.traceback:
            # Store traceback in logs
            log_entry = models.TrainingLog(
                job_id=job_id,
                log_type="stderr",
                content=f"TRACEBACK:\n{callback.traceback}"
            )
            db.add(log_entry)

    db.commit()
```

**Database Fields Updated**:
```python
class TrainingJob(Base):
    status = Column(String(20))  # "completed", "failed"
    completed_at = Column(DateTime)
    final_accuracy = Column(Float)
    best_checkpoint_path = Column(String(500))
    last_checkpoint_path = Column(String(500))
    mlflow_run_id = Column(String(100))
    error_message = Column(Text)
```

### 4.2 Testing Status

| í…ŒìŠ¤íŠ¸ í•­ëª© | ìƒíƒœ | ì¦ê±° |
|------------|------|------|
| Completion callback ìˆ˜ì‹  | âœ… í…ŒìŠ¤íŠ¸ë¨ | E2E Step 7: completion callback sent |
| Status ì—…ë°ì´íŠ¸ | âœ… í…ŒìŠ¤íŠ¸ë¨ | E2E Step 8: status=completed |
| Final metrics ì €ì¥ | âœ… í…ŒìŠ¤íŠ¸ë¨ | E2E: final_accuracy stored |
| Checkpoint paths ì €ì¥ | âœ… í…ŒìŠ¤íŠ¸ë¨ | E2E: best/last paths stored |
| Error handling | âŒ ë¯¸í…ŒìŠ¤íŠ¸ | E2EëŠ” ì„±ê³µ ì¼€ì´ìŠ¤ë§Œ í…ŒìŠ¤íŠ¸ |

**ì¶”ì²œ ì‚¬í•­**:
- [ ] Failed job completion callback í…ŒìŠ¤íŠ¸ ì¶”ê°€
- [ ] Traceback ì €ì¥ ë™ì‘ í™•ì¸

---

## 5. WebSocket Broadcasting (Backend â†’ Frontend)

### 5.1 Implementation

**íŒŒì¼**: `platform/backend/app/api/training.py:1609-1621, 1751-1765`

#### 5.1.1 Progress Updates

```python
# Broadcast to WebSocket clients
ws_manager = get_websocket_manager()
await ws_manager.broadcast_to_job(job_id, {
    "type": "training_progress",
    "job_id": job_id,
    "status": callback.status,
    "current_epoch": callback.current_epoch,
    "total_epochs": callback.total_epochs,
    "progress_percent": callback.progress_percent,
    "metrics": callback.metrics.dict() if callback.metrics else None,
    "checkpoint_path": callback.checkpoint_path,
    "best_checkpoint_path": callback.best_checkpoint_path,
})
```

#### 5.1.2 Completion Events

```python
await ws_manager.broadcast_to_job(job_id, {
    "type": "training_complete" if callback.status == "completed" else "training_error",
    "job_id": job_id,
    "status": callback.status,
    "total_epochs_completed": callback.total_epochs_completed,
    "final_metrics": callback.final_metrics.dict() if callback.final_metrics else None,
    "best_metrics": callback.best_metrics.dict() if callback.best_metrics else None,
    "best_epoch": callback.best_epoch,
    "final_checkpoint_path": callback.final_checkpoint_path,
    "best_checkpoint_path": callback.best_checkpoint_path,
    "mlflow_run_id": callback.mlflow_run_id,
    "error_message": callback.error_message,
})
```

### 5.2 WebSocket Manager

**íŒŒì¼**: `platform/backend/app/services/websocket_manager.py` (ì¶”ì •)

```python
class WebSocketManager:
    async def broadcast_to_job(self, job_id: int, message: dict):
        """Broadcast message to all clients watching this job."""
        # Send to all connected clients subscribed to this job_id
```

### 5.3 Testing Status

| í…ŒìŠ¤íŠ¸ í•­ëª© | ìƒíƒœ | ì¦ê±° |
|------------|------|------|
| WebSocket êµ¬í˜„ | âœ… êµ¬í˜„ë¨ | Code exists in training.py |
| Progress broadcast | âŒ ë¯¸í…ŒìŠ¤íŠ¸ | E2E í…ŒìŠ¤íŠ¸ì—ì„œ WebSocket í™•ì¸ ì—†ìŒ |
| Completion broadcast | âŒ ë¯¸í…ŒìŠ¤íŠ¸ | E2E í…ŒìŠ¤íŠ¸ì—ì„œ WebSocket í™•ì¸ ì—†ìŒ |
| Frontend ìˆ˜ì‹  | âš ï¸ ì•Œ ìˆ˜ ì—†ìŒ | Frontend E2E í…ŒìŠ¤íŠ¸ í•„ìš” |

**ì¶”ì²œ ì‚¬í•­**:
- [ ] WebSocket í†µí•© í…ŒìŠ¤íŠ¸ ì¶”ê°€ (Backend â†’ Frontend E2E)
- [ ] WebSocket ì—°ê²° ì‹¤íŒ¨ ì‹œ ë™ì‘ í™•ì¸

---

## 6. Data Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Trainer   â”‚ (Isolated Docker Container / Subprocess)
â”‚   Process   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€ Logs (stdout/stderr) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                                  â”‚
       â”œâ”€ Metrics â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”
       â”‚                                  â”‚     â”‚
       â”œâ”€ Checkpoints â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”
       â”‚                                  â”‚     â”‚  â”‚
       â””â”€ Results â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚     â”‚  â”‚
                                         â”‚â”‚     â”‚  â”‚
                                         â–¼â–¼     â–¼  â–¼
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚    Backend      â”‚
                                    â”‚  (training.py)  â”‚
                                    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚     â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚                                  â”‚     â”‚                  â”‚
      â–¼                                  â–¼     â”‚                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Database â”‚                      â”‚   Loki   â”‚â”‚           â”‚  WebSocket â”‚
â”‚  (Logs,  â”‚                      â”‚  (Logs)  â”‚â”‚           â”‚  (Frontend)â”‚
â”‚ Metrics, â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ Results) â”‚                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚
                                              â–¼
                                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                        â”‚  MLflow  â”‚
                                        â”‚ (Metrics)â”‚
                                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                              â–²
                                              â”‚
                                    (SDK logs directly)

Legend:
â”€â”€â”€â”€â–º Data flow through Backend
...â–º Data flow bypassing Backend (direct)
```

**Key Points**:
- Logs: Trainer â†’ Backend â†’ DB + Loki
- Metrics: Trainer SDK â†’ MLflow (ì§ì ‘), Trainer â†’ Backend â†’ DB
- Checkpoints: Trainer SDK â†’ S3 (ì§ì ‘), Trainer â†’ Backend (ê²½ë¡œë§Œ DBì—)
- Results: Trainer â†’ Backend â†’ DB
- WebSocket: Backend â†’ Frontend (ì‹¤ì‹œê°„)

---

## 7. Summary by Storage Destination

### 7.1 Database (PostgreSQL)

| í…Œì´ë¸” | ì—…ë¡œë“œ ë‹´ë‹¹ | êµ¬í˜„ ìƒíƒœ | í…ŒìŠ¤íŠ¸ ìƒíƒœ |
|--------|------------|-----------|------------|
| `training_logs` | Backend | âœ… 100% | âœ… í…ŒìŠ¤íŠ¸ë¨ |
| `training_metrics` | Backend | âœ… 100% | âœ… í…ŒìŠ¤íŠ¸ë¨ |
| `training_jobs` (results) | Backend | âœ… 100% | âœ… í…ŒìŠ¤íŠ¸ë¨ (ì„±ê³µ ì¼€ì´ìŠ¤) |

**Status**: âœ… **Database ì €ì¥ì€ ì™„ë²½í•˜ê²Œ ë™ì‘**

### 7.2 Loki (Log Aggregation)

| ê¸°ëŠ¥ | êµ¬í˜„ ìƒíƒœ | í…ŒìŠ¤íŠ¸ ìƒíƒœ |
|------|-----------|------------|
| Log ì „ì†¡ | âœ… êµ¬í˜„ë¨ (ì„ íƒì ) | âŒ ë¯¸í…ŒìŠ¤íŠ¸ |
| Log ì¡°íšŒ API | âœ… êµ¬í˜„ë¨ | âŒ ë¯¸í…ŒìŠ¤íŠ¸ |

**Status**: âš ï¸ **êµ¬í˜„ë¨ but í…ŒìŠ¤íŠ¸ ì•ˆ ë¨**

**Environment Variables**:
- `LOKI_URL`: `http://localhost:3100` (default)
- `LOKI_ENABLED`: `true` (default)

### 7.3 MLflow (Experiment Tracking)

| ê¸°ëŠ¥ | ë‹´ë‹¹ | êµ¬í˜„ ìƒíƒœ | í…ŒìŠ¤íŠ¸ ìƒíƒœ |
|------|------|-----------|------------|
| Metric ë¡œê¹… | **Trainer SDK** | âœ… SDK êµ¬í˜„ | âš ï¸ SDK í…ŒìŠ¤íŠ¸ |
| Run ID ì €ì¥ | Backend | âœ… êµ¬í˜„ë¨ | âœ… í…ŒìŠ¤íŠ¸ë¨ |
| Metric ì¡°íšŒ | Backend (read-only) | âœ… êµ¬í˜„ë¨ | âœ… í…ŒìŠ¤íŠ¸ë¨ |

**Status**: âœ… **BackendëŠ” read-only, SDKê°€ ì—…ë¡œë“œ ë‹´ë‹¹**

**Critical**: Backendì˜ MLflow clientëŠ” read-only wrapperì…ë‹ˆë‹¤.

### 7.4 S3/MinIO (Object Storage)

| ê¸°ëŠ¥ | ë‹´ë‹¹ | êµ¬í˜„ ìƒíƒœ | í…ŒìŠ¤íŠ¸ ìƒíƒœ |
|------|------|-----------|------------|
| Checkpoint ì—…ë¡œë“œ | **Trainer SDK** | âœ… SDK êµ¬í˜„ | âš ï¸ Mocked in test |
| Checkpoint ê²½ë¡œ ì €ì¥ | Backend | âœ… êµ¬í˜„ë¨ | âœ… í…ŒìŠ¤íŠ¸ë¨ |

**Status**: âœ… **BackendëŠ” ê²½ë¡œë§Œ ì €ì¥, SDKê°€ ì—…ë¡œë“œ ë‹´ë‹¹**

### 7.5 WebSocket (Frontend Real-time)

| ê¸°ëŠ¥ | êµ¬í˜„ ìƒíƒœ | í…ŒìŠ¤íŠ¸ ìƒíƒœ |
|------|-----------|------------|
| Progress broadcast | âœ… êµ¬í˜„ë¨ | âŒ ë¯¸í…ŒìŠ¤íŠ¸ |
| Completion broadcast | âœ… êµ¬í˜„ë¨ | âŒ ë¯¸í…ŒìŠ¤íŠ¸ |

**Status**: âš ï¸ **êµ¬í˜„ë¨ but í…ŒìŠ¤íŠ¸ ì•ˆ ë¨**

---

## 8. Testing Coverage Summary

### 8.1 Tested (âœ…)

| ê¸°ëŠ¥ | í…ŒìŠ¤íŠ¸ íŒŒì¼ | Step |
|------|------------|------|
| Log â†’ DB ì €ì¥ | test_training_e2e.py | Step 9 |
| Metric â†’ DB ì €ì¥ | test_training_e2e.py | Step 6 |
| Checkpoint path â†’ DB | test_training_e2e.py | Step 7 |
| Result â†’ DB ì €ì¥ | test_training_e2e.py | Step 8 |
| MLflow run_id ì €ì¥ | test_training_e2e.py | Step 7 |
| DB ì¡°íšŒ API | test_training_e2e.py | Step 8, 9 |

### 8.2 Not Tested (âŒ)

| ê¸°ëŠ¥ | ì´ìœ  | ìš°ì„ ìˆœìœ„ |
|------|------|---------|
| Loki ì „ì†¡ | Loki ì„œë²„ ì—†ìŒ | Medium |
| Loki ì¡°íšŒ API | Loki ì„œë²„ ì—†ìŒ | Low |
| WebSocket broadcast | E2E í…ŒìŠ¤íŠ¸ ë²”ìœ„ ë°– | High |
| Failed job handling | ì„±ê³µ ì¼€ì´ìŠ¤ë§Œ í…ŒìŠ¤íŠ¸ | High |
| Traceback ì €ì¥ | ì‹¤íŒ¨ ì¼€ì´ìŠ¤ ì—†ìŒ | Medium |

### 8.3 Partially Tested (âš ï¸)

| ê¸°ëŠ¥ | í˜„ì¬ ìƒíƒœ | ëˆ„ë½ ë¶€ë¶„ |
|------|----------|----------|
| Checkpoint upload | Mocked S3 paths | ì‹¤ì œ S3 ì—…ë¡œë“œ í…ŒìŠ¤íŠ¸ |
| MLflow logging | SDK ë‚´ë¶€ ë™ì‘ | Backendì™€ì˜ í†µí•© í…ŒìŠ¤íŠ¸ |

---

## 9. Recommendations

### 9.1 High Priority

1. **WebSocket E2E Test**
   - [ ] Backend â†’ Frontend WebSocket í†µí•© í…ŒìŠ¤íŠ¸ ì¶”ê°€
   - [ ] Progress update ìˆ˜ì‹  í™•ì¸
   - [ ] Completion event ìˆ˜ì‹  í™•ì¸

2. **Failed Job Test**
   - [ ] SDKì—ì„œ ì—ëŸ¬ ë°œìƒ ì‹œ Backend ë™ì‘ í™•ì¸
   - [ ] Traceback ì €ì¥ í™•ì¸
   - [ ] Error message ì „íŒŒ í™•ì¸

3. **Error Handling Test Suite**
   - [ ] SDK callback ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ ë¡œì§ í…ŒìŠ¤íŠ¸
   - [ ] DB ì €ì¥ ì‹¤íŒ¨ ì‹œ fallback ë™ì‘ í™•ì¸
   - [ ] Loki ì „ì†¡ ì‹¤íŒ¨ ì‹œ ë¡œê·¸ ì†ì‹¤ ì—†ìŒ í™•ì¸

### 9.2 Medium Priority

4. **Loki Integration Test**
   - [ ] Docker Composeì— Loki ì¶”ê°€
   - [ ] Log ì „ì†¡ í™•ì¸
   - [ ] Log ì¡°íšŒ API í…ŒìŠ¤íŠ¸

5. **S3 Upload Test**
   - [ ] Mocked S3 ëŒ€ì‹  ì‹¤ì œ MinIO ì‚¬ìš©
   - [ ] Checkpoint ì—…ë¡œë“œ í™•ì¸
   - [ ] Presigned URL ìƒì„± í…ŒìŠ¤íŠ¸

### 9.3 Low Priority

6. **MLflow Integration Test**
   - [ ] SDK â†’ MLflow ë¡œê¹… í™•ì¸
   - [ ] Backend MLflow ì¡°íšŒ API ì •í™•ë„ í™•ì¸

7. **Performance Test**
   - [ ] ëŒ€ëŸ‰ ë¡œê·¸ ì €ì¥ ì„±ëŠ¥ (1000+ lines)
   - [ ] DB batch insert ìµœì í™” í™•ì¸

---

## 10. Conclusion

### âœ… Backendê°€ ì˜ í•˜ê³  ìˆëŠ” ê²ƒ

1. **Database ì €ì¥**: ë¡œê·¸, ë©”íŠ¸ë¦­, ê²°ê³¼ë¥¼ DBì— ì™„ë²½íˆ ì €ì¥
2. **Callback ì²˜ë¦¬**: SDKë¡œë¶€í„° callbackì„ ì •í™•íˆ ìˆ˜ì‹ í•˜ê³  ì²˜ë¦¬
3. **Path ê´€ë¦¬**: ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œë¥¼ DBì— ì •í™•íˆ ì €ì¥
4. **MLflow ë§í¬**: run_idë¥¼ ì €ì¥í•˜ì—¬ MLflowì™€ ì—°ë™

### âš ï¸ Backendê°€ í•˜ì§€ ì•ŠëŠ” ê²ƒ (By Design)

1. **MLflow ë©”íŠ¸ë¦­ ì—…ë¡œë“œ**: SDKê°€ ì§ì ‘ MLflowì— ë¡œê¹… (ì˜ë„ëœ ì„¤ê³„)
2. **Checkpoint ì—…ë¡œë“œ**: SDKê°€ S3ì— ì§ì ‘ ì—…ë¡œë“œ (ì˜ë„ëœ ì„¤ê³„)

### âŒ í…ŒìŠ¤íŠ¸ê°€ í•„ìš”í•œ ê²ƒ

1. **WebSocket ë¸Œë¡œë“œìºìŠ¤íŠ¸**: êµ¬í˜„ë¨, í…ŒìŠ¤íŠ¸ í•„ìš”
2. **Loki í†µí•©**: êµ¬í˜„ë¨, í…ŒìŠ¤íŠ¸ í•„ìš”
3. **ì‹¤íŒ¨ ì¼€ì´ìŠ¤**: ì—ëŸ¬ í•¸ë“¤ë§ í…ŒìŠ¤íŠ¸ í•„ìš”

### ğŸ“Š Overall Status

| ì¹´í…Œê³ ë¦¬ | ìƒíƒœ |
|---------|------|
| **êµ¬í˜„ ì™„ì„±ë„** | 95% (WebSocket í…ŒìŠ¤íŠ¸ë§Œ í•„ìš”) |
| **í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€** | 70% (ì„±ê³µ ì¼€ì´ìŠ¤ ì¤‘ì‹¬) |
| **Production Ready** | âš ï¸ ì¶”ê°€ í…ŒìŠ¤íŠ¸ í›„ ê°€ëŠ¥ |

**Next Steps**:
1. WebSocket E2E í…ŒìŠ¤íŠ¸ ì¶”ê°€ (Frontend í†µí•©)
2. Failed job í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ì¶”ê°€
3. Loki í†µí•© í…ŒìŠ¤íŠ¸ (ì„ íƒì )

---

**Report Generated**: 2025-11-20
**Author**: Claude Code
**Related Documents**:
- [TRAINING_SDK_E2E_TEST_REPORT.md](TRAINING_SDK_E2E_TEST_REPORT.md)
- [TRAINING_PIPELINE_DESIGN.md](TRAINING_PIPELINE_DESIGN.md)
- [IMPLEMENTATION_TO_DO_LIST.md](../IMPLEMENTATION_TO_DO_LIST.md)
